{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary PyTorch modules for building neural networks\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Define the Discriminator class that inherits from nn.Module\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, channels_img, features_d):\n",
    "        # Call the __init__ method of nn.Module (the parent class)\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        # Define the sequential model (a linear stack of layers) for the discriminator network\n",
    "        self.disc = nn.Sequential(\n",
    "            # First convolutional layer\n",
    "            # Input shape: (N, channels_img, 64, 64), where N is the batch size, channels_img is the number of input channels\n",
    "            nn.Conv2d(\n",
    "                channels_img,  # Number of input channels (e.g., 3 for RGB images)\n",
    "                features_d,     # Number of output channels (depth) for this layer (controls the feature maps)\n",
    "                kernel_size=4,  # Size of the convolutional filter (4x4)\n",
    "                stride=2,       # How much the filter moves across the image (2 pixels at a time)\n",
    "                padding=1       # Padding added around the image to maintain size after convolution\n",
    "            ),\n",
    "            # Apply LeakyReLU activation to add non-linearity\n",
    "            # LeakyReLU allows a small, non-zero gradient when the unit is not active\n",
    "            nn.LeakyReLU(0.2),  # Negative slope of 0.2 to avoid vanishing gradients for negative values\n",
    "\n",
    "            # Second block: Convolution + BatchNorm + LeakyReLU\n",
    "            # This block will downsample the image and learn more complex features\n",
    "            self._block(features_d, features_d * 2, 4, 2, 1),  # Increases depth (number of feature maps)\n",
    "            \n",
    "            # Third block: Same structure with more filters (features_d * 2 to features_d * 4)\n",
    "            self._block(features_d * 2, features_d * 4, 4, 2, 1),\n",
    "            \n",
    "            # Fourth block: Same structure with even more filters (features_d * 4 to features_d * 8)\n",
    "            self._block(features_d * 4, features_d * 8, 4, 2, 1),\n",
    "            \n",
    "            # Final block: Convolution to reduce the output to a single value (the \"real\" or \"fake\" prediction)\n",
    "            # Output shape will be (N, 1, 1, 1), where N is the batch size, 1 represents the final output\n",
    "            nn.Conv2d(\n",
    "                features_d * 8,  # Input depth (number of feature maps)\n",
    "                1,               # Output depth is 1 (single prediction for real or fake)\n",
    "                kernel_size=4,    # 4x4 filter\n",
    "                stride=2,         # Stride of 2 for downsampling\n",
    "                padding=1         # Padding to ensure proper dimensionality\n",
    "            ),\n",
    "            \n",
    "            # Sigmoid activation function: It squashes the output between 0 and 1\n",
    "            # This is useful for binary classification (real or fake)\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    # A helper method to create a block of Conv2D -> BatchNorm -> LeakyReLU layers\n",
    "    def _block(self, in_channels, out_channels, kernel_size, stride, padding):\n",
    "        return nn.Sequential(\n",
    "            # Convolutional layer\n",
    "            nn.Conv2d(\n",
    "                in_channels,   # Input depth (from the previous layer)\n",
    "                out_channels,  # Output depth (number of feature maps this layer produces)\n",
    "                kernel_size,   # Filter size (e.g., 4x4)\n",
    "                stride,        # Stride for downsampling\n",
    "                padding,       # Padding to keep the image size consistent\n",
    "                bias=False     # No bias term as BatchNorm takes care of it\n",
    "            ),\n",
    "            # Batch normalization helps stabilize training by normalizing the output of the Conv layer\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            # Apply LeakyReLU activation function\n",
    "            nn.LeakyReLU(0.2),\n",
    "        )\n",
    "    \n",
    "    # Forward method: Defines how the input tensor (image) flows through the network layers\n",
    "    def forward(self, x):\n",
    "        # Pass the input 'x' (image) through the 'disc' network (the sequential layers)\n",
    "        return self.disc(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 78\u001b[0m\n\u001b[0;32m     76\u001b[0m         Print(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSuccess\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     77\u001b[0m \u001b[38;5;66;03m# Call the test function to run the test on the Generator and Discriminator\u001b[39;00m\n\u001b[1;32m---> 78\u001b[0m \u001b[43mtest\u001b[49m()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'test' is not defined"
     ]
    }
   ],
   "source": [
    "class Generator(nn.Module):\n",
    "    # The Generator class, which is a neural network that creates new images from random noise (z_dim).\n",
    "    def __init__(self, z_dim, channels_img, features_g):\n",
    "        # Constructor method to initialize the Generator with:\n",
    "        # - z_dim: the dimension of the input noise vector\n",
    "        # - channels_img: number of output channels (e.g., 3 for RGB images)\n",
    "        # - features_g: number of feature maps to use in the generator\n",
    "        super(Generator, self).__init__()  # Call the parent class initializer\n",
    "\n",
    "        # Define the layers of the Generator using nn.Sequential (a container for layers in sequence)\n",
    "        self.gen = nn.Sequential(\n",
    "            # First layer: Convert noise (z_dim) into a large number of feature maps\n",
    "            # Input: N (batch size) x z_dim x 1 x 1 (random noise)\n",
    "            self._block(z_dim, features_g*16, 4, 1, 0),  # Output: N x (features_g*16) x 4 x 4\n",
    "\n",
    "            # Second layer: Upsample to 8x8\n",
    "            self._block(features_g*16, features_g*8, 4, 2, 1),  # Output: N x (features_g*8) x 8 x 8\n",
    "\n",
    "            # Third layer: Upsample to 16x16\n",
    "            self._block(features_g*8, features_g*4, 4, 2, 1),  # Output: N x (features_g*4) x 16 x 16\n",
    "\n",
    "            # Fourth layer: Upsample to 32x32\n",
    "            self._block(features_g*4, features_g*2, 4, 2, 1),  # Output: N x (features_g*2) x 32 x 32\n",
    "\n",
    "            # Final layer: Convert feature maps to an image with the correct number of channels (RGB)\n",
    "            nn.ConvTranspose2d(\n",
    "                features_g*2, channels_img, kernel_size=4, stride=2, padding=1  # Output: N x channels_img x 64 x 64\n",
    "            ),\n",
    "            \n",
    "            # Tanh activation function to ensure pixel values are between -1 and 1 (commonly used for images)\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "\n",
    "    def _block(self, in_channels, out_channels, kernel_size, stride, padding):\n",
    "        # This helper method defines a block of layers: ConvTranspose2d, BatchNorm2d, and ReLU.\n",
    "        # Used to build the layers of the Generator.\n",
    "        return nn.Sequential(\n",
    "            nn.ConvTranspose2d(\n",
    "                in_channels,  # Number of input feature maps\n",
    "                out_channels,  # Number of output feature maps\n",
    "                kernel_size,  # Size of the convolution kernel\n",
    "                stride,  # Stride of the convolution (controls upsampling)\n",
    "                padding,  # Padding to control the output size\n",
    "                bias=False,  # Disable bias since we are using BatchNorm\n",
    "            ),\n",
    "            nn.BatchNorm2d(out_channels),  # Normalize the feature maps (helps training stability)\n",
    "            nn.ReLU(),  # ReLU activation function (introduces non-linearity)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        return self.gen(x)\n",
    "\n",
    "    @staticmethod\n",
    "    def initialize_weights(model):\n",
    "        # Initialize the weights of the Conv2D, ConvTranspose2D, and BatchNorm layers with a normal distribution\n",
    "        # This helps the model start training with reasonable weights.\n",
    "        for m in model.modules():\n",
    "            if isinstance(m, (nn.Conv2d, nn.ConvTranspose2d, nn.BatchNorm2d)):\n",
    "                nn.init.normal_(m.weight.data, 0.0, 0.2)  # Mean=0.0, Standard Deviation=0.2 for weight initialization\n",
    "\n",
    "    @staticmethod\n",
    "    def test():\n",
    "        # A test function to check if the Generator and Discriminator work as expected\n",
    "        N, in_channels, H, W = 8, 3, 64, 64  # Define batch size (N), input channels (RGB), and image size (64x64)\n",
    "        z_dim = 100  # Dimension of the noise vector (latent space)\n",
    "        \n",
    "        x = torch.randn((N, in_channels, H, W))  # Create a random batch of images (used for testing the discriminator)\n",
    "        disc = Discriminator(in_channels, 8)  # Instantiate the Discriminator with 8 feature maps\n",
    "        Generator.initialize_weights(disc)  # Initialize the weights of the Discriminator\n",
    "        assert disc(x).shape == (N, 1, 1)  # Assert the output shape of the Discriminator is (N, 1, 1)\n",
    "        gen = Generator(z_dim, in_channels, 8)\n",
    "        Generator.initialize_weights(gen)\n",
    "        z = torch. randn((N, z_dim, 1, 1))\n",
    "        assert gen(z).shape == (N, in_channels, H, W)\n",
    "        Print(\"Success\")\n",
    "# Call the test function to run the test on the Generator and Discriminator\n",
    "test()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes are correct!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, z_dim, channels_img, features_g):\n",
    "        super(Generator, self).__init__()\n",
    "        \n",
    "        # Generator model architecture\n",
    "        self.gen = nn.Sequential(\n",
    "            # Upsample from noise vector (z_dim x 1 x 1) to a 4x4 feature map\n",
    "            self._block(z_dim, features_g * 16, 4, 1, 0),  # Output: N x (features_g*16) x 4 x 4\n",
    "            \n",
    "            # Upsample to 8x8\n",
    "            self._block(features_g * 16, features_g * 8, 4, 2, 1),  # Output: N x (features_g*8) x 8 x 8\n",
    "            \n",
    "            # Upsample to 16x16\n",
    "            self._block(features_g * 8, features_g * 4, 4, 2, 1),  # Output: N x (features_g*4) x 16 x 16\n",
    "            \n",
    "            # Upsample to 32x32\n",
    "            self._block(features_g * 4, features_g * 2, 4, 2, 1),  # Output: N x (features_g*2) x 32 x 32\n",
    "            \n",
    "            # Final upsample to 64x64 and convert to image with `channels_img` channels (e.g., 3 for RGB)\n",
    "            nn.ConvTranspose2d(features_g * 2, channels_img, kernel_size=4, stride=2, padding=1),  # Output: N x channels_img x 64 x 64\n",
    "            \n",
    "            # Use Tanh activation to scale pixel values between -1 and 1\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def _block(self, in_channels, out_channels, kernel_size, stride, padding):\n",
    "        # Helper method to create a ConvTranspose2d block\n",
    "        return nn.Sequential(\n",
    "            nn.ConvTranspose2d(in_channels, out_channels, kernel_size, stride, padding, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.gen(x)\n",
    "\n",
    "    @staticmethod\n",
    "    def initialize_weights(model):\n",
    "        # Initialize the weights of Conv layers using a normal distribution\n",
    "        for m in model.modules():\n",
    "            if isinstance(m, (nn.Conv2d, nn.ConvTranspose2d, nn.BatchNorm2d)):\n",
    "                nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, channels_img, features_d):\n",
    "        super(Discriminator, self).__init__()\n",
    "        \n",
    "        # Discriminator model architecture\n",
    "        self.disc = nn.Sequential(\n",
    "            # Input is an image with shape (channels_img) x 64 x 64\n",
    "            nn.Conv2d(channels_img, features_d, kernel_size=4, stride=2, padding=1),  # Output: N x features_d x 32 x 32\n",
    "            nn.LeakyReLU(0.2),\n",
    "            \n",
    "            # Downsample to 16x16\n",
    "            self._block(features_d, features_d * 2, 4, 2, 1),  # Output: N x (features_d*2) x 16 x 16\n",
    "            \n",
    "            # Downsample to 8x8\n",
    "            self._block(features_d * 2, features_d * 4, 4, 2, 1),  # Output: N x (features_d*4) x 8 x 8\n",
    "            \n",
    "            # Downsample to 4x4\n",
    "            self._block(features_d * 4, features_d * 8, 4, 2, 1),  # Output: N x (features_d*8) x 4 x 4\n",
    "            \n",
    "            # Final layer: 4x4 to 1x1 output, for binary classification (real/fake)\n",
    "            nn.Conv2d(features_d * 8, 1, kernel_size=4, stride=1, padding=0),  # Output: N x 1 x 1 x 1\n",
    "            nn.Sigmoid()  # Use sigmoid to output probability of real/fake\n",
    "        )\n",
    "\n",
    "    def _block(self, in_channels, out_channels, kernel_size, stride, padding):\n",
    "        # Helper method to create a Conv2d block\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.LeakyReLU(0.2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.disc(x).view(-1, 1)  # Flatten the output to (N, 1) for binary classification\n",
    "\n",
    "    @staticmethod\n",
    "    def initialize_weights(model):\n",
    "        # Initialize the weights of Conv layers using a normal distribution\n",
    "        for m in model.modules():\n",
    "            if isinstance(m, (nn.Conv2d, nn.ConvTranspose2d, nn.BatchNorm2d)):\n",
    "                nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "\n",
    "\n",
    "# Test function to verify if the shapes are correct\n",
    "def test():\n",
    "    N, in_channels, H, W = 8, 3, 64, 64  # Batch size, input channels, and image size\n",
    "    z_dim = 100  # Latent space dimension\n",
    "\n",
    "    # Create random batch of images (to test the Discriminator)\n",
    "    x = torch.randn((N, in_channels, H, W))\n",
    "    \n",
    "    # Instantiate the Discriminator and Generator\n",
    "    disc = Discriminator(in_channels, 8)\n",
    "    gen = Generator(z_dim, in_channels, 8)\n",
    "\n",
    "    # Initialize the weights of both models\n",
    "    Discriminator.initialize_weights(disc)\n",
    "    Generator.initialize_weights(gen)\n",
    "\n",
    "    # Test the Discriminator output shape\n",
    "    assert disc(x).shape == (N, 1), f\"Discriminator output shape mismatch: {disc(x).shape}\"\n",
    "    \n",
    "    # Test the Generator output shape\n",
    "    z = torch.randn((N, z_dim, 1, 1))  # Random noise input for the generator\n",
    "    assert gen(z).shape == (N, in_channels, H, W), f\"Generator output shape mismatch: {gen(z).shape}\"\n",
    "    \n",
    "    print(\"Shapes are correct!\")\n",
    "\n",
    "# Call the test function\n",
    "test()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, channels_noise, channels_img, features_g):\n",
    "        super(Generator, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            # Input: N x channels_noise x 1 x 1\n",
    "            self._block(channels_noise, features_g * 16, 4, 1, 0),  # img: 4x4\n",
    "            self._block(features_g * 16, features_g * 8, 4, 2, 1),  # img: 8x8\n",
    "            self._block(features_g * 8, features_g * 4, 4, 2, 1),  # img: 16x16\n",
    "            self._block(features_g * 4, features_g * 2, 4, 2, 1),  # img: 32x32\n",
    "            nn.ConvTranspose2d(\n",
    "                features_g * 2, channels_img, kernel_size=4, stride=2, padding=1\n",
    "            ),\n",
    "            # Output: N x channels_img x 64 x 64\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "\n",
    "    def _block(self, in_channels, out_channels, kernel_size, stride, padding):\n",
    "        return nn.Sequential(\n",
    "            nn.ConvTranspose2d(\n",
    "                in_channels,\n",
    "                out_channels,\n",
    "                kernel_size,\n",
    "                stride,\n",
    "                padding,\n",
    "                bias=False,\n",
    "            ),\n",
    "            # nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "\n",
    "def initialize_weights(model):\n",
    "    # Initializes weights according to the DCGAN paper\n",
    "    for m in model.modules():\n",
    "        if isinstance(m, (nn.Conv2d, nn.ConvTranspose2d, nn.BatchNorm2d)):\n",
    "            nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "\n",
    "\n",
    "def test():\n",
    "    N, in_channels, H, W = 8, 3, 64, 64\n",
    "    noise_dim = 100\n",
    "    x = torch.randn((N, in_channels, H, W))\n",
    "    disc = Discriminator(in_channels, 8)\n",
    "    assert disc(x).shape == (N, 1, 1, 1), \"Discriminator test failed\"\n",
    "    gen = Generator(noise_dim, in_channels, 8)\n",
    "    z = torch.randn((N, noise_dim, 1, 1))\n",
    "    assert gen(z).shape == (N, in_channels, H, W), \"Generator test failed\"\n",
    "    print(\"Success, tests passed!\")\n",
    "\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "    test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
